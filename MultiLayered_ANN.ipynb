{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9909b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58663f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 데이터 로드 및 준비 ---\n",
    "# 전처리 완료된 데이터 삽입\n",
    "df = pd.read_csv('adolescent_health_data.csv')\n",
    "\n",
    "\n",
    "# --- 2. Prefix 정의 및 칼럼 그룹핑 ---\n",
    "# 이미지에 나온 prefix들을 리스트로 정의합니다.\n",
    "# 'M'은 타겟이므로 제외합니다.\n",
    "prefixes = [\n",
    "    'TC_', 'AC_', 'WC_', 'PA_', 'F_', 'I_', 'V_', 'S_', 'O_',\n",
    "    'HW_', 'AS_', 'RH_', 'ECZ_', 'INT_', 'DR_', 'E_'\n",
    "]\n",
    "\n",
    "# 타겟 칼럼(M으로 시작)과 피처 칼럼을 분리합니다.\n",
    "m_targets = [col for col in df.columns if col.startswith('M_')]\n",
    "all_features = [col for col in df.columns if col not in m_targets]\n",
    "\n",
    "# Prefix별로 피처 칼럼을 그룹핑합니다.\n",
    "feature_groups = {}\n",
    "no_prefix_features = []\n",
    "\n",
    "for feature in all_features:\n",
    "    found_prefix = False\n",
    "    for prefix in prefixes:\n",
    "        if feature.startswith(prefix):\n",
    "            if prefix not in feature_groups:\n",
    "                feature_groups[prefix] = []\n",
    "            feature_groups[prefix].append(feature)\n",
    "            found_prefix = True\n",
    "            break\n",
    "    if not found_prefix:\n",
    "        # 어떤 prefix에도 속하지 않는 칼럼들 (예: 'user_id', 'age' 등)\n",
    "        no_prefix_features.append(feature)\n",
    "\n",
    "# Prefix 없는 피처들도 하나의 그룹으로 추가\n",
    "if no_prefix_features:\n",
    "    feature_groups['NO_PREFIX_'] = no_prefix_features\n",
    "\n",
    "print(\"✅ 타겟 (M_):\", m_targets)\n",
    "print(\"✅ 그룹핑된 피처:\")\n",
    "for prefix, cols in feature_groups.items():\n",
    "    print(f\"  - {prefix}: {cols}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a94743",
   "metadata": {},
   "source": [
    "# --- 3. 각 타겟에 대해 개별 모델 학습 (반복문) ---\n",
    "history_dict = {} # 모델별 학습 기록 저장\n",
    "\n",
    "for target_col in m_targets:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🚀 모델 학습 시작: Target = {target_col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # 데이터 분리 (매번 동일하게 분리하기 위해 random_state 고정)\n",
    "    X = df[all_features]\n",
    "    y = df[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Keras Functional API를 사용한 모델 구축 ---\n",
    "    # 1단계: Prefix 그룹별 입력 및 1차 처리 레이어\n",
    "    input_layers = []\n",
    "    processed_outputs = []\n",
    "\n",
    "    for prefix, cols in feature_groups.items():\n",
    "        # 각 그룹에 맞는 입력층 생성\n",
    "        group_input = Input(shape=(len(cols),), name=f'input_{prefix}')\n",
    "        input_layers.append(group_input)\n",
    "        \n",
    "        # 각 그룹을 하나의 노드로 압축하는 Dense 레이어\n",
    "        # 그룹의 특성을 요약하는 역할을 합니다.\n",
    "        group_output = Dense(1, activation='relu', name=f'processed_{prefix}')(group_input)\n",
    "        processed_outputs.append(group_output)\n",
    "\n",
    "    # 2단계: 1차 처리된 노드들 결합\n",
    "    # 모든 그룹의 요약 노드들을 하나로 합칩니다.\n",
    "    concatenated = Concatenate()(processed_outputs)\n",
    "\n",
    "    # (선택) 중간에 은닉층(Hidden Layer) 추가\n",
    "    # 더 복잡한 관계를 학습하고 싶을 때 추가합니다. 16개 노드 사용.\n",
    "    hidden_layer = Dense(16, activation='relu', name='hidden_layer_1')(concatenated)\n",
    "\n",
    "    # 3단계: 최종 출력 레이어\n",
    "    # 타겟 변수를 예측합니다. (이진 분류로 가정하여 sigmoid 사용)\n",
    "    output_layer = Dense(1, activation='sigmoid', name='output_layer')(hidden_layer)\n",
    "    \n",
    "    # 모델 정의\n",
    "    # feature_groups의 순서에 맞게 실제 데이터를 넣어주기 위해 입력 데이터를 리스트로 준비\n",
    "    model_inputs = [X_train[cols] for prefix, cols in feature_groups.items()]\n",
    "    test_inputs = [X_test[cols] for prefix, cols in feature_groups.items()]\n",
    "\n",
    "    model = Model(inputs=list(input_layers), outputs=output_layer)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', # 타겟이 0 또는 1일 경우\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        model_inputs,\n",
    "        y_train,\n",
    "        validation_data=(test_inputs, y_test),\n",
    "        epochs=10, # 실제 데이터에 맞게 조절\n",
    "        batch_size=32,\n",
    "        verbose=0 # 학습 과정 로그 생략 (1로 바꾸면 보임)\n",
    "    )\n",
    "\n",
    "    history_dict[target_col] = history\n",
    "    print(f\"✅ 모델 학습 완료: {target_col}\")\n",
    "    \n",
    "    # 모델 평가\n",
    "    loss, accuracy = model.evaluate(test_inputs, y_test)\n",
    "    print(f\"📈 테스트 정확도: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31385079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (1, 2번 코드는 위와 동일) ---\n",
    "\n",
    "# --- 3. 다중 출력 모델 구축 및 학습 ---\n",
    "history_dict = {} # 모델별 학습 기록 저장\n",
    "\n",
    "for target_col in m_targets:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🚀 모델 학습 시작: Target = {target_col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# 데이터 분리\n",
    "X = df[all_features]\n",
    "y = df[m_targets] # y를 모든 M_ 칼럼으로 지정\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Keras Functional API를 사용한 모델 구축 ---\n",
    "# 1단계: Prefix 그룹별 입력 및 1차 처리 레이어\n",
    "input_layers = []\n",
    "processed_outputs = []\n",
    "\n",
    "for prefix, cols in feature_groups.items():\n",
    "    group_input = Input(shape=(len(cols),), name=f'input_{prefix}')\n",
    "    input_layers.append(group_input)\n",
    "    group_output = Dense(1, activation='relu', name=f'processed_{prefix}')(group_input)\n",
    "    processed_outputs.append(group_output)\n",
    "\n",
    "# 2단계: 1차 처리된 노드들 결합\n",
    "concatenated = Concatenate()(processed_outputs)\n",
    "hidden_layer = Dense(16, activation='relu', name='hidden_layer_1')(concatenated)\n",
    "\n",
    "# 3단계: 최종 출력 레이어\n",
    "# 출력 노드 수를 타겟 칼럼의 개수(len(m_targets))로 설정합니다.\n",
    "output_layer = Dense(len(m_targets), activation='sigmoid', name='output_layer')(hidden_layer)\n",
    "\n",
    "# 모델 정의\n",
    "model_inputs = [X_train[cols] for prefix, cols in feature_groups.items()]\n",
    "test_inputs = [X_test[cols] for prefix, cols in feature_groups.items()]\n",
    "\n",
    "multi_output_model = Model(inputs=list(input_layers), outputs=output_layer)\n",
    "\n",
    "# 모델 컴파일\n",
    "multi_output_model.compile(optimizer='adam',\n",
    "                           loss='binary_crossentropy', # 모든 출력이 이진 분류일 경우\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "multi_output_model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "print(\"\\n🚀 다중 출력 모델 학습 시작...\")\n",
    "history = multi_output_model.fit(\n",
    "    model_inputs,\n",
    "    y_train,\n",
    "    validation_data=(test_inputs, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "print(\"✅ 다중 출력 모델 학습 완료!\")\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = multi_output_model.evaluate(test_inputs, y_test)\n",
    "print(f\"📈 테스트 정확도: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
