{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9909b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58663f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„ ---\n",
    "# ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„° ì‚½ì…\n",
    "df = pd.read_csv('adolescent_health_data.csv')\n",
    "\n",
    "\n",
    "# --- 2. Prefix ì •ì˜ ë° ì¹¼ëŸ¼ ê·¸ë£¹í•‘ ---\n",
    "# ì´ë¯¸ì§€ì— ë‚˜ì˜¨ prefixë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "# 'M'ì€ íƒ€ê²Ÿì´ë¯€ë¡œ ì œì™¸í•©ë‹ˆë‹¤.\n",
    "prefixes = [\n",
    "    'TC_', 'AC_', 'WC_', 'PA_', 'F_', 'I_', 'V_', 'S_', 'O_',\n",
    "    'HW_', 'AS_', 'RH_', 'ECZ_', 'INT_', 'DR_', 'E_'\n",
    "]\n",
    "\n",
    "# íƒ€ê²Ÿ ì¹¼ëŸ¼(Mìœ¼ë¡œ ì‹œì‘)ê³¼ í”¼ì²˜ ì¹¼ëŸ¼ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "m_targets = [col for col in df.columns if col.startswith('M_')]\n",
    "all_features = [col for col in df.columns if col not in m_targets]\n",
    "\n",
    "# Prefixë³„ë¡œ í”¼ì²˜ ì¹¼ëŸ¼ì„ ê·¸ë£¹í•‘í•©ë‹ˆë‹¤.\n",
    "feature_groups = {}\n",
    "no_prefix_features = []\n",
    "\n",
    "for feature in all_features:\n",
    "    found_prefix = False\n",
    "    for prefix in prefixes:\n",
    "        if feature.startswith(prefix):\n",
    "            if prefix not in feature_groups:\n",
    "                feature_groups[prefix] = []\n",
    "            feature_groups[prefix].append(feature)\n",
    "            found_prefix = True\n",
    "            break\n",
    "    if not found_prefix:\n",
    "        # ì–´ë–¤ prefixì—ë„ ì†í•˜ì§€ ì•ŠëŠ” ì¹¼ëŸ¼ë“¤ (ì˜ˆ: 'user_id', 'age' ë“±)\n",
    "        no_prefix_features.append(feature)\n",
    "\n",
    "# Prefix ì—†ëŠ” í”¼ì²˜ë“¤ë„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ì¶”ê°€\n",
    "if no_prefix_features:\n",
    "    feature_groups['NO_PREFIX_'] = no_prefix_features\n",
    "\n",
    "print(\"âœ… íƒ€ê²Ÿ (M_):\", m_targets)\n",
    "print(\"âœ… ê·¸ë£¹í•‘ëœ í”¼ì²˜:\")\n",
    "for prefix, cols in feature_groups.items():\n",
    "    print(f\"  - {prefix}: {cols}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a94743",
   "metadata": {},
   "source": [
    "# --- 3. ê° íƒ€ê²Ÿì— ëŒ€í•´ ê°œë³„ ëª¨ë¸ í•™ìŠµ (ë°˜ë³µë¬¸) ---\n",
    "history_dict = {} # ëª¨ë¸ë³„ í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
    "\n",
    "for target_col in m_targets:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘: Target = {target_col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # ë°ì´í„° ë¶„ë¦¬ (ë§¤ë²ˆ ë™ì¼í•˜ê²Œ ë¶„ë¦¬í•˜ê¸° ìœ„í•´ random_state ê³ ì •)\n",
    "    X = df[all_features]\n",
    "    y = df[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Keras Functional APIë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ êµ¬ì¶• ---\n",
    "    # 1ë‹¨ê³„: Prefix ê·¸ë£¹ë³„ ì…ë ¥ ë° 1ì°¨ ì²˜ë¦¬ ë ˆì´ì–´\n",
    "    input_layers = []\n",
    "    processed_outputs = []\n",
    "\n",
    "    for prefix, cols in feature_groups.items():\n",
    "        # ê° ê·¸ë£¹ì— ë§ëŠ” ì…ë ¥ì¸µ ìƒì„±\n",
    "        group_input = Input(shape=(len(cols),), name=f'input_{prefix}')\n",
    "        input_layers.append(group_input)\n",
    "        \n",
    "        # ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ ë…¸ë“œë¡œ ì••ì¶•í•˜ëŠ” Dense ë ˆì´ì–´\n",
    "        # ê·¸ë£¹ì˜ íŠ¹ì„±ì„ ìš”ì•½í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "        group_output = Dense(1, activation='relu', name=f'processed_{prefix}')(group_input)\n",
    "        processed_outputs.append(group_output)\n",
    "\n",
    "    # 2ë‹¨ê³„: 1ì°¨ ì²˜ë¦¬ëœ ë…¸ë“œë“¤ ê²°í•©\n",
    "    # ëª¨ë“  ê·¸ë£¹ì˜ ìš”ì•½ ë…¸ë“œë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.\n",
    "    concatenated = Concatenate()(processed_outputs)\n",
    "\n",
    "    # (ì„ íƒ) ì¤‘ê°„ì— ì€ë‹‰ì¸µ(Hidden Layer) ì¶”ê°€\n",
    "    # ë” ë³µì¡í•œ ê´€ê³„ë¥¼ í•™ìŠµí•˜ê³  ì‹¶ì„ ë•Œ ì¶”ê°€í•©ë‹ˆë‹¤. 16ê°œ ë…¸ë“œ ì‚¬ìš©.\n",
    "    hidden_layer = Dense(16, activation='relu', name='hidden_layer_1')(concatenated)\n",
    "\n",
    "    # 3ë‹¨ê³„: ìµœì¢… ì¶œë ¥ ë ˆì´ì–´\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (ì´ì§„ ë¶„ë¥˜ë¡œ ê°€ì •í•˜ì—¬ sigmoid ì‚¬ìš©)\n",
    "    output_layer = Dense(1, activation='sigmoid', name='output_layer')(hidden_layer)\n",
    "    \n",
    "    # ëª¨ë¸ ì •ì˜\n",
    "    # feature_groupsì˜ ìˆœì„œì— ë§ê²Œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë„£ì–´ì£¼ê¸° ìœ„í•´ ì…ë ¥ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¤€ë¹„\n",
    "    model_inputs = [X_train[cols] for prefix, cols in feature_groups.items()]\n",
    "    test_inputs = [X_test[cols] for prefix, cols in feature_groups.items()]\n",
    "\n",
    "    model = Model(inputs=list(input_layers), outputs=output_layer)\n",
    "\n",
    "    # ëª¨ë¸ ì»´íŒŒì¼\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy', # íƒ€ê²Ÿì´ 0 ë˜ëŠ” 1ì¼ ê²½ìš°\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    # ëª¨ë¸ í•™ìŠµ\n",
    "    history = model.fit(\n",
    "        model_inputs,\n",
    "        y_train,\n",
    "        validation_data=(test_inputs, y_test),\n",
    "        epochs=10, # ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ì¡°ì ˆ\n",
    "        batch_size=32,\n",
    "        verbose=0 # í•™ìŠµ ê³¼ì • ë¡œê·¸ ìƒëµ (1ë¡œ ë°”ê¾¸ë©´ ë³´ì„)\n",
    "    )\n",
    "\n",
    "    history_dict[target_col] = history\n",
    "    print(f\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {target_col}\")\n",
    "    \n",
    "    # ëª¨ë¸ í‰ê°€\n",
    "    loss, accuracy = model.evaluate(test_inputs, y_test)\n",
    "    print(f\"ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31385079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- (1, 2ë²ˆ ì½”ë“œëŠ” ìœ„ì™€ ë™ì¼) ---\n",
    "\n",
    "# --- 3. ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ ---\n",
    "history_dict = {} # ëª¨ë¸ë³„ í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
    "\n",
    "for target_col in m_targets:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘: Target = {target_col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# ë°ì´í„° ë¶„ë¦¬\n",
    "X = df[all_features]\n",
    "y = df[m_targets] # yë¥¼ ëª¨ë“  M_ ì¹¼ëŸ¼ìœ¼ë¡œ ì§€ì •\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Keras Functional APIë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ êµ¬ì¶• ---\n",
    "# 1ë‹¨ê³„: Prefix ê·¸ë£¹ë³„ ì…ë ¥ ë° 1ì°¨ ì²˜ë¦¬ ë ˆì´ì–´\n",
    "input_layers = []\n",
    "processed_outputs = []\n",
    "\n",
    "for prefix, cols in feature_groups.items():\n",
    "    group_input = Input(shape=(len(cols),), name=f'input_{prefix}')\n",
    "    input_layers.append(group_input)\n",
    "    group_output = Dense(1, activation='relu', name=f'processed_{prefix}')(group_input)\n",
    "    processed_outputs.append(group_output)\n",
    "\n",
    "# 2ë‹¨ê³„: 1ì°¨ ì²˜ë¦¬ëœ ë…¸ë“œë“¤ ê²°í•©\n",
    "concatenated = Concatenate()(processed_outputs)\n",
    "hidden_layer = Dense(16, activation='relu', name='hidden_layer_1')(concatenated)\n",
    "\n",
    "# 3ë‹¨ê³„: ìµœì¢… ì¶œë ¥ ë ˆì´ì–´\n",
    "# ì¶œë ¥ ë…¸ë“œ ìˆ˜ë¥¼ íƒ€ê²Ÿ ì¹¼ëŸ¼ì˜ ê°œìˆ˜(len(m_targets))ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "output_layer = Dense(len(m_targets), activation='sigmoid', name='output_layer')(hidden_layer)\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model_inputs = [X_train[cols] for prefix, cols in feature_groups.items()]\n",
    "test_inputs = [X_test[cols] for prefix, cols in feature_groups.items()]\n",
    "\n",
    "multi_output_model = Model(inputs=list(input_layers), outputs=output_layer)\n",
    "\n",
    "# ëª¨ë¸ ì»´íŒŒì¼\n",
    "multi_output_model.compile(optimizer='adam',\n",
    "                           loss='binary_crossentropy', # ëª¨ë“  ì¶œë ¥ì´ ì´ì§„ ë¶„ë¥˜ì¼ ê²½ìš°\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "multi_output_model.summary()\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "print(\"\\nğŸš€ ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "history = multi_output_model.fit(\n",
    "    model_inputs,\n",
    "    y_train,\n",
    "    validation_data=(test_inputs, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "print(\"âœ… ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "loss, accuracy = multi_output_model.evaluate(test_inputs, y_test)\n",
    "print(f\"ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
